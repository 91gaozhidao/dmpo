######################################################################
# environment and task
env_suite: gym
env: hopper-medium-v2

# future action forecasts
action_dim: 3
horizon_steps: 4

# observation history
obs_dim: 11
cond_steps: 1

# dispersive loss naming for file naming
dispersive_weight_name: "0p5"     # corresponding to dispersive_loss_weight: 0.5
dispersive_temp_name: "0p5"       # corresponding to dispersive_temperature: 0.5
dispersive_type_name: "infnce"    # corresponding to dispersive_loss_type: "infonce_l2"
###################################################################

defaults:
  - _self_
hydra:
  run:
    dir: ${logdir}
_target_: agent.pretrain.train_shortcut_dispersive_agent.TrainMeanFlowDispersiveAgent
name: ${env}_pre_meanflow_dispersive_mlp_ta${horizon_steps}_${dispersive_type_name}_d${dispersive_weight_name}_t${dispersive_temp_name}
logdir: ${oc.env:REINFLOW_LOG_DIR}/gym/pretrain/${name}/${now:%Y-%m-%d}_${now:%H-%M-%S}_${seed}
# Download from Hugging Face automatically (recommended)
train_dataset_path: hf://gym/${env}/train.npz
normalization_path: hf://gym/${env}/normalization.npz
# Or use local path:
# train_dataset_path: ${oc.env:REINFLOW_DATA_DIR}/gym/${env}/train.npz
# normalization_path: ${oc.env:REINFLOW_DATA_DIR}/gym/${env}/normalization.npz
use_d4rl_dataset: True

# MeanFlow parameters
flow_ratio: 0.5  # ratio of samples using flow consistency (r=t)
gamma: 0.5       # parameter for adaptive L2 loss
c: 1e-3          # stability constant for adaptive loss

batch_size: 128  # aligned with other MeanFlow variants
seed: 42
device: cuda:0
test_in_mujoco: True
auto_resume: True  # automatically resume from the latest checkpoint if available
max_n_episodes: -1
wandb:
  entity: ${oc.env:REINFLOW_WANDB_ENTITY}
  project: DM1-gym-${env}-pretrain
  run: ${now:%H-%M-%S}_${name}

train:
  n_epochs: 40  # aligned with MeanFlow
  batch_size: ${batch_size}
  learning_rate: 1e-3  # aligned with MeanFlow
  weight_decay: 1e-6
  lr_scheduler:
    first_cycle_steps: 40  # aligned with n_epochs
    warmup_steps: 5
    min_lr: 1e-4
  save_model_freq: 10
  test_freq: 10

model:
  _target_: model.flow.shortcut_dispersive.MeanFlowDispersive
  network:
    _target_: model.flow.mlp_meanflow.MeanFlowMLP
    action_dim: ${action_dim}
    horizon_steps: ${horizon_steps}
    cond_dim: ${eval:'${obs_dim} * ${cond_steps}'}
    time_dim: 16
    r_embedding_dim: 16
    mlp_dims: [512, 512, 512]
    cond_mlp_dims: [64, 16]
    activation_type: Mish
    out_activation_type: Identity
    use_layernorm: false
    residual_style: true
  device: ${device}
  horizon_steps: ${horizon_steps}
  action_dim: ${action_dim}
  act_min: -1
  act_max: 1
  obs_dim: ${obs_dim}
  max_denoising_steps: 5  # MeanFlow designed for 1-step generation
  seed: ${seed}
  flow_ratio: ${flow_ratio}
  gamma: ${gamma}
  c: ${c}
  sample_t_type: lognormal
  use_adaptive_loss: false
  # Dispersive Loss parameters
  dispersive_loss_weight: 0.5        # Weight coefficient for dispersive loss
  dispersive_loss_type: "infonce_l2"  # Type: infonce_l2, infonce_cosine, hinge, covariance
  dispersive_temperature: 0.5        # Temperature for InfoNCE variants (optimal from paper)
  dispersive_margin: 1.0             # Margin for hinge loss
  apply_dispersive_to_embeddings: true   # Apply to embeddings (time, r, condition)

ema:
  decay: 0.995

train_dataset:
  _target_: agent.dataset.sequence.StitchedSequenceDataset
  dataset_path: ${train_dataset_path}
  horizon_steps: ${horizon_steps}
  cond_steps: ${cond_steps}
  device: ${device}
  max_n_episodes: ${max_n_episodes}
