# dmpo: Dispersive MeanFlow Policy Optimization
# One Step Is Enough: Dispersive MeanFlow Policy Optimization

__version__ = "1.0.0"
__author__ = "Anonymous"
__package__ = "dmpo"
